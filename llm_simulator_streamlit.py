import streamlit as st
import os
from openai import OpenAI
from dotenv import load_dotenv

# Charger les variables d'environnement √† partir d'un fichier .env
load_dotenv()

# Initialiser le client OpenAI avec la cl√© API provenant des variables d'environnement
client = OpenAI(api_key=os.environ.get('OPENAI_API_KEY'))

def generate_response(prompt_text):
    """
    G√©n√©rer une r√©ponse en utilisant l'API OpenAI.
    
    Args:
    prompt_text (str): Le texte d'entr√©e de l'utilisateur pour g√©n√©rer une r√©ponse.

    Returns:
    str: Le texte de r√©ponse g√©n√©r√©.
    """
    # Appel √† l'API OpenAI pour g√©n√©rer une r√©ponse bas√©e sur le prompt_text
    response = client.chat.completions.create(
        model="gpt-3.5-turbo",  # Sp√©cifier le mod√®le √† utiliser
        messages=[  # D√©finir le contexte de la conversation
            {
                "role": "system",
                "content": prompt_text
            },
            {
                "role": "user",
                "content": ""
            }
        ],
        temperature=1,  # Contr√¥le la randomisation : des valeurs plus √©lev√©es signifient des r√©ponses plus al√©atoires
        max_tokens=256,  # La longueur maximale de la r√©ponse g√©n√©r√©e
        top_p=1,  # √âchantillonnage du noyau : des valeurs plus √©lev√©es encouragent la diversit√©
        frequency_penalty=0,  # Diminue la probabilit√© de r√©p√©ter des mots
        presence_penalty=0  # Encourage de nouveaux concepts dans le texte
    )
    # Extraire et retourner le texte g√©n√©r√© √† partir de la r√©ponse
    text = response.choices[0].message.content.strip()
    return text

# Configuration de l'application Streamlit pour un style am√©lior√©
st.title("üß† Partenaire Conversationnel AI")


st.markdown("""
Bienvenue dans cette application simplifi√©e de g√©n√©ration de texte AI ! Cette interface conviviale vous permet de g√©n√©rer du texte √† partir de vos propres instructions. Id√©al pour tout utilisateur, aucune connaissance informatique pr√©alable n'est requise.
""")


# Zone de texte pour l'entr√©e de l'utilisateur
instruction = st.text_area("Veuillez renseigner vos instructions ici", height=100, key="prompt")

# Configuration de la mise en page en utilisant des colonnes pour l'alignement
col1, col2 = st.columns([0.8, 0.2])

with col1:
    # Bouton G√©n√©rer pour d√©clencher la g√©n√©ration de r√©ponse
    if st.button("G√©n√©rer", key="generate"):
        with st.spinner('ü§ñ L\'AI r√©fl√©chit...'):  # Affiche un spinner pendant le traitement
            response = generate_response(instruction)
            st.text_area("R√©ponse :", value=response, height=500, key="response", help="R√©ponse de l'AI")

with col2:
    st.write("")  # Utilis√© pour des fins d'alignement
    if st.button("Effacer", key="clear"):
        # Effacer le texte d'instruction ; correction par rapport √† la version pr√©c√©dente
        st.session_state.prompt = ""

# Barre lat√©rale pour des informations suppl√©mentaires sur l'application et les d√©tails de configuration
with st.sidebar:
    st.markdown("## Configuration de l'App")
    st.markdown("""
- **Mod√®le Utilis√© :** GPT-3.5 Turbo
- **Temp√©rature :** 1
- **Max Tokens :** 256
- **Top P :** 1
- **P√©nalit√© de Fr√©quence :** 0
- **P√©nalit√© de Pr√©sence :** 0
    """)

    st.markdown("## √Ä propos")
    st.write("Cette application est aliment√©e par le GPT-3.5 Turbo d'OpenAI, con√ßue pour r√©pondre √† vos questions, engager une conversation significative et plus encore.")


# Adding the GitHub link as credits
st.markdown('Cr√©√© par : [El Mehdi Jebbour](https://github.com/ElMehdijebbour)', unsafe_allow_html=True)